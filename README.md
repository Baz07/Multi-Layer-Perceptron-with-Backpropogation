# Multi-Layer-Perceptron-with-Backpropogation (Without using Libraries such as Keras, Tensorflow or Pytorch)
- Implemented MLP with Back Propogation in order to distinguish between 4 classes.

- Dataset contains 24754 samples, each with 784 features divided into 4 classes (0, 1, 2, 3). Dataset was divided into Training and Validation Set.

- Code: One Single Function that will allow to use the network for prediction of testing data. It will output labels as One Hot Encoded in a numpy array.

## Final Results:
#### Validation Accuracy :  94.42030245089519 % with following parameters:
1. Input Layer Neurons = 784
2. Hidden Layer Neurons = 10
3. Output Layer Neurons = 4
4. Learning rate = 0.1
5. Number of Epochs = 160
